{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`In this NB we would Learn and Apply ARIMA Model`**. As well doing the necessary Model validation.\n",
    "\n",
    "This NB is continuation of 9_C_Time Series Forecasting_Concepts + Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasting a Time Series\n",
    "--\n",
    "\n",
    "Now that we have made the Time series stationary, let’s make models on the time series using differencing because it is easy to add the error , trend and seasonality back into predicted values.\n",
    "\n",
    "We will use statistical modelling method called `ARIMA to forecast the data`.\n",
    "\n",
    "**ARIMA stands for Autoregressive Integrated Moving Average models**. Univariate (single vector) ARIMA is a forecasting technique that projects the future values of a series based entirely on its own inertia. `Its main application is in the area of short term forecasting requiring at least 40 historical data points`. It works best when your data exhibits a stable or consistent pattern over time with a minimum amount of outliers. Sometimes called `Box-Jenkins` (after the original authors), ARIMA is usually superior to exponential smoothing techniques when the data is reasonably long and the correlation between past observations is stable. If the data is short or highly volatile, then some smoothing method may perform better. If you do not have at least 38 data points, you should consider some other method than ARIMA.\n",
    "\n",
    "**`Basic Concepts:`**\n",
    "\n",
    "The first step in applying ARIMA methodology **is to check for stationarity**. \"Stationarity\" implies that the series remains at a fairly constant level over time. If a trend exists, as in most economic or business applications, then your data is NOT stationary. The data should also show a constant variance in its fluctuations over time. This is easily seen with a series that is heavily seasonal and growing at a faster rate. In such a case, the ups and downs in the seasonality will become more dramatic over time. Without these stationarity conditions being met, many of the calculations associated with the process cannot be computed. *(we did **\"Stationarity\"** in NB 9_B and 9_C )*\n",
    "\n",
    "\n",
    "**`Differencing`**:\n",
    "\n",
    "If a graphical plot of the data indicates nonstationarity, then you should \"difference\" the series. Differencing is an excellent way of transforming a nonstationary series to a stationary one. This is done by subtracting the observation in the current period from the previous one. If this transformation is done only once to a series, you say that the data has been \"first differenced\"( means d=1 ). This process essentially eliminates the trend if your series is growing at a fairly constant rate. If it is growing at an increasing rate, you can apply the same procedure and difference the data again. Your data would then be \"second differenced\"( means d=2 ). \n",
    "\n",
    "**`Autocorrelations`**\n",
    "\n",
    "\"Autocorrelations\" are numerical values that indicate how a data series is related to itself over time. More precisely, it measures how strongly data values at a specified number of periods apart are correlated to each other over time. The number of periods apart is usually called the \"lag\". For example, an autocorrelation at lag 1 measures how values 1 period apart are correlated to one another throughout the series. An autocorrelation at lag 2 measures how the data two periods apart are correlated throughout the series. Autocorrelations may range from +1 to -1. A value close to +1 indicates a high positive correlation while a value close to -1 implies a high negative correlation.\n",
    "\n",
    "\n",
    "**`Autoregressive Models`**:\n",
    "\n",
    "ARIMA methodology attempts to describe the movements in a stationary time series as a function of what are called \"autoregressive and moving average\" parameters. These are referred to as AR parameters (autoregessive) and MA parameters (moving averages). An AR model with only 1 parameter may be written as...\n",
    "\n",
    "X(t) = A(1) * X(t-1) + E(t)\n",
    "\n",
    "where X(t) = time series under investigation\n",
    "\n",
    "A(1) = the autoregressive parameter of order 1\n",
    "\n",
    "X(t-1) = the time series lagged 1 period\n",
    "\n",
    "E(t) = the error term of the model\n",
    "\n",
    "This simply means that any given value X(t) can be explained by some function of its previous value, X(t-1), plus some unexplainable random error, E(t). If the estimated value of A(1) was .30, then the current value of the series would be related to 30% of its value 1 period ago. Of course, the series could be related to more than just one past value. For example,\n",
    "\n",
    "X(t) = A(1) * X(t-1) + A(2) * X(t-2) + E(t)\n",
    "\n",
    "This indicates that the current value of the series is a combination of the two immediately preceding values, X(t-1) and X(t-2), plus some random error E(t). Our model is now an autoregressive model of order 2.\n",
    "\n",
    "**`Moving Average Models`**:\n",
    "\n",
    "A second type of Box-Jenkins model is called a \"moving average\" model. Although these models look very similar to the AR model, the concept behind them is quite different. Moving average parameters relate what happens in period t only to the random errors that occurred in past time periods, i.e. E(t-1), E(t-2), etc. rather than to X(t-1), X(t-2), (Xt-3) as in the autoregressive approaches. A moving average model with one MA term may be written as follows...\n",
    "\n",
    "X(t) = -B(1) * E(t-1) + E(t)\n",
    "\n",
    "The term B(1) is called an MA of order 1. The negative sign in front of the parameter is used for convention only and is usually printed out auto- matically by most computer programs. The above model simply says that any given value of X(t) is directly related only to the random error in the previous period, E(t-1), and to the current error term, E(t). As in the case of autoregressive models, the moving average models can be extended to higher order structures covering different combinations and moving average lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Mixed Models`**:\n",
    "\n",
    "ARIMA methodology also allows models to be built that incorporate both autoregressive and moving average parameters together. These models are often referred to as \"mixed models\". Although this makes for a more complicated forecasting tool, the structure may indeed simulate the series better and produce a more accurate forecast. Pure models imply that the structure consists only of AR or MA parameters - not both.\n",
    "\n",
    "The models developed by this approach are usually called `ARIMA models because they use a combination of autoregressive (AR), integration (I) - referring to the reverse process of differencing to produce the forecast, and moving average (MA) operations`. An ARIMA model is usually stated as **`ARIMA(p,d,q)`**. This represents the order of the autoregressive components (p), the number of differencing operators (d), and the highest order of the moving average term(q). For example, ARIMA(2,1,1) means that you have a second order autoregressive model with a first order moving average component whose series has been differenced once to induce stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Important`** : Parameters (p,d,q) of the ARIMA model.\n",
    "\n",
    "Let me explain these dependent parameters:\n",
    "\n",
    "• p : This is the number of AR (Auto-Regressive) terms or The number of lag observations included in the model, also called the lag order.\n",
    "\n",
    "**`Example`** — if p is 3 the predictor for y(t) will be y(t-1),y(t-2),y(t-3).\n",
    "\n",
    "\n",
    "• d :This is the number of differences or the number of non-seasonal differences. \n",
    "\n",
    "**`Example`** - \n",
    "d=0: no differencing (no trends)\n",
    "\n",
    "d=1: perform differencing once (linear trend)\n",
    "\n",
    "d=2: double differencing\n",
    "\n",
    "\n",
    "• q : The size of the moving average window. q is the number of lagged forecast errors in the prediction equation (MA part). This allows us to set the error of our model as a linear combination of the error values observed at previous time points in the past. \n",
    "\n",
    "**`Example`** - an MA of order 1 means that X(t) is directly related only to the random error in the previous period, E(t-1), and to the current error term, E(t)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developing(or Coding) ARIMA Model\n",
    "--\n",
    "In this section, we will develop Autoregressive Integrated Moving Average or ARIMA models for the \"annual water usage in Baltimore\" problem. ( **refer : yearly-water-usage.csv** )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Manually Configuring the ARIMA`**\n",
    "\n",
    "The ARIMA(p,d,q) model requires three parameters and is traditionally configured manually. (*Therefore using ARIMA is more of an art than Science*)\n",
    "\n",
    "Analysis of the time series data assumes that we are working with a stationary time series.\n",
    "\n",
    "The time series is likely non-stationary. We can make it stationary by first differencing the series and using a statistical test to confirm that the result is stationary. ( **already done in NB 9_C** )\n",
    "\n",
    "The next first step is to select the lag values for the Autoregression (AR) and Moving Average (MA) parameters, p and q respectively.\n",
    "\n",
    "We can do this by reviewing **`Autocorrelation Function (ACF)`** and **`Partial Autocorrelation Function (PACF)`** plots.\n",
    "\n",
    "`Note` : *In the field of time series analysis, autocorrelation refers to the correlation of a time series with a lagged version of itself. For example, an autocorrelation of order 3 returns the correlation between a time series and its own values lagged by 3 time points.*\n",
    "\n",
    "It is common to use the autocorrelation `(ACF) plot`, also known as self-autocorrelation, to visualize the autocorrelation of a time-series. The `plot_acf()` function in the statsmodels library can be used to measure and plot the autocorrelation of a time series.\n",
    "\n",
    "The example below creates ACF and PACF plots for the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# load data\n",
    "series = read_csv('C:\\Program Files/Python36/suven/Data Anaylsis/Dataset/yearly-water-usage.csv', header=0, index_col=0)\n",
    "\n",
    "fig = pyplot.figure()\n",
    "fig.subplots_adjust(hspace=0.6)\n",
    "pyplot.subplot(211)\n",
    "plot_acf(series, ax=pyplot.gca()) # gca -> \"GetCurrentAxis\"\n",
    "# Plots lags on the horizontal and the correlations on vertical axis.\n",
    "\n",
    "pyplot.subplot(212)\n",
    "plot_pacf(series, ax=pyplot.gca())\n",
    "pyplot.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`How to Read the above ACF and PACF plots ?`\n",
    "--\n",
    "and \n",
    "**`also how to deduce p and q values for ARIMA`**\n",
    "\n",
    "**plot_acf(series)** \n",
    "Running the example creates a 2D plot showing the `lag value` along the **x-axis** and the `correlation` on the y-axis between **-1 and 1**.\n",
    "\n",
    "`Confidence intervals` are drawn as a cone. By default, this is set to a `95% confidence interval`, suggesting that correlation values outside of this cone are very likely a correlation and not a statistical fluke.\n",
    "\n",
    "> `Tip` : By default, all lag values are printed, which makes the plot noisy.\n",
    "We can limit the number of lags on the x-axis like this :\n",
    "`plot_acf(series, lags=50)`\n",
    "to make the plot easier to read. In our case yearly-water-usage.csv has fewer values.\n",
    "\n",
    "**Now let’s check out on how we can figure out what value of p and q to use**. We have used two popular plotting techniques above; they are:\n",
    "\n",
    "• `Autocorrelation Function (ACF)`: It just measures the correlation between two consecutive (lagged version). example at lag 4, ACF will compare series at time instance t1…t2 with series at instance t1–4…t2–4\n",
    "\n",
    "• `Partial Autocorrelation Function (PACF)`: is used to measure the degree of association between y(t) and y(t-p).\n",
    "\n",
    "• p: The point where the PACF crosses the upper confidence interval and is the highest, here its 0 ( *look at x = 0* ). hence p = 0. This means at lag = 0, we get the highest correlation. \n",
    "\n",
    "• q: The point where the ACF crosses the upper confidence interval and is the highest. Here its close to 0. hence q = 0.\n",
    "\n",
    "**`This quick analysis suggests an ARIMA(0,1,0) on the raw data may be a good starting point`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Predicted=495.579, Expected=503\n",
      ">Predicted=506.769, Expected=503\n",
      ">Predicted=506.675, Expected=450\n",
      ">Predicted=452.293, Expected=432\n",
      ">Predicted=433.810, Expected=432\n",
      ">Predicted=433.767, Expected=458\n",
      ">Predicted=460.318, Expected=462\n",
      ">Predicted=464.356, Expected=503\n",
      ">Predicted=506.196, Expected=488\n",
      ">Predicted=490.809, Expected=466\n",
      ">Predicted=468.292, Expected=492\n",
      ">Predicted=494.776, Expected=503\n",
      ">Predicted=505.940, Expected=515\n",
      ">Predicted=518.118, Expected=500\n",
      ">Predicted=502.769, Expected=522\n",
      ">Predicted=525.132, Expected=575\n",
      ">Predicted=579.056, Expected=583\n",
      ">Predicted=587.127, Expected=587\n",
      ">Predicted=591.125, Expected=628\n",
      ">Predicted=632.772, Expected=640\n",
      ">Predicted=644.897, Expected=609\n",
      ">Predicted=613.288, Expected=606\n",
      ">Predicted=610.167, Expected=632\n",
      ">Predicted=636.525, Expected=617\n",
      ">Predicted=621.210, Expected=613\n",
      ">Predicted=617.079, Expected=598\n",
      ">Predicted=601.781, Expected=575\n",
      ">Predicted=578.369, Expected=564\n",
      ">Predicted=567.152, Expected=549\n",
      ">Predicted=551.881, Expected=538\n",
      ">Predicted=540.676, Expected=568\n",
      ">Predicted=571.072, Expected=575\n",
      ">Predicted=578.129, Expected=579\n",
      ">Predicted=582.141, Expected=587\n",
      ">Predicted=590.208, Expected=602\n",
      ">Predicted=605.370, Expected=594\n",
      ">Predicted=597.216, Expected=587\n",
      ">Predicted=590.080, Expected=587\n",
      ">Predicted=590.039, Expected=625\n",
      ">Predicted=628.494, Expected=613\n",
      "RMSE: 21.655\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from math import sqrt\n",
    "\n",
    "# load data\n",
    "series = read_csv('C:\\Program Files/Python36/suven/Data Anaylsis/Dataset/yearly-water-usage.csv', header=0, index_col=0)\n",
    "\n",
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "\n",
    "train_size = int(len(X) * 0.50)\n",
    "train, test = X[0:train_size], X[train_size:]\n",
    "\n",
    "# walk-forward validation\n",
    "history = [x for x in train]#to_list()\n",
    "predictions = list()\n",
    "\n",
    "for i in range(len(test)):\n",
    "\t# predict\n",
    "\tmodel = ARIMA(history, order=(0,1,0))\n",
    "\tmodel_fit = model.fit(disp=0) \n",
    "    # By default, disp parameter is set to 1, which shows convergence output.\n",
    "    # Set disp to 0, because it is critical in removing all of the convergence output when evaluating the ARIMA model using walk-forward validation.\n",
    "    # Setting it to False turns off all of this noise i.e extra unwanted o/p.\n",
    "\tyhat = model_fit.forecast()[0] #returns 3 values hence we take the 0th term\n",
    "\tpredictions.append(yhat)\n",
    "\t# observation\n",
    "\tobs = test[i]\n",
    "\thistory.append(obs)\n",
    "\tprint('>Predicted=%.3f, Expected=%3.f' % (yhat, obs))\n",
    "    \n",
    "# report performance\n",
    "mse = mean_squared_error(test, predictions)\n",
    "rmse = sqrt(mse)\n",
    "print('RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search ARIMA Hyperparameters**\n",
    "\n",
    "The ACF and PACF plots suggest that we cannot do better than a **persistence model on this dataset.** (`in persistence model we got rmse of approx 21.658` - see **NB 9_C**)\n",
    "\n",
    "To confirm this analysis, we can grid search a suite of ARIMA hyperparameters and check that no models result in better out of sample RMSE performance.\n",
    "\n",
    "In this section, we will search values of p, d, and q combinations and find the combination that results in the best performance. We will use a grid search to explore all combinations in a subset of integer values.\n",
    "\n",
    "Specifically, we will search all combinations of the following parameters:\n",
    "\n",
    "`p: 0 to 4.`\n",
    "\n",
    "`d: 0 to 2.`\n",
    "\n",
    "`q: 0 to 4.`\n",
    "\n",
    "This is (5 * 3 * 5), or 75 potential runs of the test harness, and will take some time to execute. We will **also disable** the automatic addition of a trend constant from the model by setting the ‘trend‘ argument to ‘nc‘ for no constant when calling fit().\n",
    "\n",
    "> **Note** : The \"trend\" Parameter : The trend parameter adds an additional constant term to the model. Think of it like a `bias or intercept term`.\n",
    "It is described as: Whether to include a constant or not. 'c' includes constant, 'nc' no constant. By default, a trend term is enabled with trend set to ‘c‘."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA(0, 0, 1) RMSE=288.153\n",
      "ARIMA(0, 0, 2) RMSE=165.011\n",
      "ARIMA(0, 0, 3) RMSE=98.734\n",
      "ARIMA(0, 0, 4) RMSE=76.216\n",
      "ARIMA(0, 1, 1) RMSE=21.627\n",
      "ARIMA(0, 1, 2) RMSE=21.834\n",
      "ARIMA(0, 1, 3) RMSE=23.956\n",
      "ARIMA(0, 1, 4) RMSE=24.075\n",
      "ARIMA(0, 2, 1) RMSE=21.703\n",
      "ARIMA(0, 2, 2) RMSE=21.640\n",
      "ARIMA(0, 2, 3) RMSE=21.686\n",
      "ARIMA(0, 2, 4) RMSE=25.219\n",
      "ARIMA(1, 0, 0) RMSE=22.005\n",
      "ARIMA(1, 1, 0) RMSE=21.636\n",
      "ARIMA(1, 2, 0) RMSE=27.398\n",
      "ARIMA(1, 2, 1) RMSE=21.658\n",
      "ARIMA(1, 2, 2) RMSE=23.273\n",
      "ARIMA(2, 0, 0) RMSE=21.995\n",
      "ARIMA(2, 1, 0) RMSE=21.426\n",
      "ARIMA(2, 2, 0) RMSE=25.105\n",
      "ARIMA(2, 2, 3) RMSE=24.727\n",
      "ARIMA(3, 0, 0) RMSE=21.881\n",
      "ARIMA(3, 1, 0) RMSE=23.402\n",
      "ARIMA(3, 1, 1) RMSE=24.094\n",
      "ARIMA(3, 2, 0) RMSE=24.438\n",
      "ARIMA(3, 2, 1) RMSE=23.395\n",
      "ARIMA(4, 0, 0) RMSE=23.732\n",
      "ARIMA(4, 1, 0) RMSE=23.635\n",
      "ARIMA(4, 1, 1) RMSE=23.966\n",
      "ARIMA(4, 1, 2) RMSE=23.974\n",
      "ARIMA(4, 2, 0) RMSE=25.686\n",
      "ARIMA(4, 2, 1) RMSE=23.623\n",
      "ARIMA(4, 2, 2) RMSE=23.813\n",
      "Best ARIMA(2, 1, 0) RMSE=21.426\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pandas import read_csv\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    " \n",
    "# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "\t# prepare training dataset\n",
    "\tX = X.astype('float32')\n",
    "\ttrain_size = int(len(X) * 0.50)\n",
    "\ttrain, test = X[0:train_size], X[train_size:]\n",
    "\thistory = [x for x in train]\n",
    "\t# make predictions\n",
    "\tpredictions = list()\n",
    "\tfor t in range(len(test)):\n",
    "\t\tmodel = ARIMA(history, order=arima_order)\n",
    "\t\t# model_fit = model.fit(disp=0)\n",
    "\t\tmodel_fit = model.fit(trend='nc', disp=0) #disp=0 stops arima from displaying the values\n",
    "\t\tyhat = model_fit.forecast()[0] # [0] -> indicates the value of the forecast\n",
    "        # see syntax of forecast function here -> \n",
    "        # http://www.statsmodels.org/stable/generated/statsmodels.tsa.arima_model.ARIMAResults.forecast.html?highlight=forecast#statsmodels.tsa.arima_model.ARIMAResults.forecast\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\thistory.append(test[t])\n",
    "\t# calculate out of sample error\n",
    "\tmse = mean_squared_error(test, predictions)\n",
    "\trmse = sqrt(mse)\n",
    "\treturn rmse\n",
    " \n",
    "# evaluate combinations of p, d and q values for an ARIMA model\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "\tdataset = dataset.astype('float32')\n",
    "\tbest_score, best_cfg = float(\"inf\"), None\n",
    "\tfor p in p_values:\n",
    "\t\tfor d in d_values:\n",
    "\t\t\tfor q in q_values:\n",
    "\t\t\t\torder = (p,d,q)\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tmse = evaluate_arima_model(dataset, order)\n",
    "\t\t\t\t\tif mse < best_score:\n",
    "\t\t\t\t\t\tbest_score, best_cfg = mse, order\n",
    "\t\t\t\t\tprint('ARIMA%s RMSE=%.3f' % (order,mse))\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tcontinue\n",
    "\tprint('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n",
    " # load data\n",
    "series = read_csv('C:\\Program Files/Python36/suven/Data Anaylsis/Dataset/yearly-water-usage.csv', header=0, index_col=0)\n",
    "\n",
    "# evaluate parameters\n",
    "p_values = range(0,5)\n",
    "d_values = range(0,3)\n",
    "q_values = range(0,5)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(series.values,p_values,d_values,q_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the best configuration discovered was ____________ with an RMSE of ______, slightly lower than the manual persistence model **tested earlier in NB 9_C.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Prediction: \n",
    "--\n",
    "Load/Use the finalized model and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([608.49653874, 609.56465725, 610.08325858, 609.9932122 ]), array([32.69860456, 47.24018087, 56.35012907, 64.04111523]), array([[544.40845145, 672.58462603],\n",
      "       [516.97560412, 702.15371038],\n",
      "       [499.63903509, 720.52748207],\n",
      "       [484.47493283, 735.51149158]]))\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "series = read_csv('C:\\Program Files/Python36/suven/Data Anaylsis/Dataset/yearly-water-usage.csv', header=0, index_col=0)\n",
    "\n",
    "# prepare data\n",
    "X = series.values\n",
    "X = X.astype('float32')\n",
    "\n",
    "# fit model\n",
    "model = ARIMA(X,order=(2,1,0))\n",
    "model_fit=model.fit(trend='nc',disp=0)\n",
    "# http://www.statsmodels.org/stable/generated/statsmodels.tsa.arima_model.ARIMA.fit.html?highlight=arima%20fit#statsmodels.tsa.arima_model.ARIMA.fit\n",
    "yhat = model_fit.forecast(steps=4,alpha=0.05)\n",
    "\n",
    "\n",
    "# default alpha=0.05  i.e 95% confidence\n",
    "# check the syntax of forecast here\n",
    "# http://www.statsmodels.org/stable/generated/statsmodels.tsa.arima_model.ARIMAResults.forecast.html?highlight=forecast#statsmodels.tsa.arima_model.ARIMAResults.forecast\n",
    "print(yhat)\n",
    "\n",
    "# we are predicting 4 new values -> see first array\n",
    "# in 2nd array -> we get the Array of the standard errors, of the forecasts.\n",
    "# in 3rd array -> we get 2d array of the confidence interval for the forecast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
